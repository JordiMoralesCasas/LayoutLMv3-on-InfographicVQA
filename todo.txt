For generation, fix error in tokenizer (fixed?)

Better load_state section

change boolean console parameters (from 1/0 to bool) 

MORE PARAMETERS FOR RUNNER:
    unify model_folder and checkpoint (maybe checkpoint being a boolean for training frm the model_folder model), use the pretained_model arg
    results file name
    Choose scheduler/optimizer (not prioritary rn)
    TODO in modelling.get_optimizers

Document all the functions

When using load_state, do evaluation before training so we don't overwrite the previous best model if the new is worse

Adaptive embedder doesn't work when daloader batch bigger than 2, actually fails in data collator

Batch size in adaptive embedder during evaluation slightly affects results

split train/test from model_runner.py




